\bb
\ii Let $V=\{A\in M_{nn}\colon A \text{ is invertible}\}$. Show that the usual matrix addition and scalar multiplication do NOT make $V$ into a vector space. 
\\
\begin{solution}
We know already that matrix addition and scalar multiplication satisfy {\em most} of the vector space axioms: e.g., commutativity, distributivity, etc. 

However the operations fail to be well-defined defined on the given set! That is the sum of two matrices in $V$ does not necessarily lie in $V$. 

As a concrete counterexample, take $I_n$ and $-I_n$. Both are invertible matrices, and thus lie in $V$. However, $I_n+(-I_n)=\boldzero_n$, the zero matrix, which does not lie in $V$. 

Note also that scalar multiplication is also not well-defined on $V$: if we scale any invertible matrix $A$ by the scalar $c=0$, then we get the zero matrix, which is not in $V$. 
\end{solution}
\ii Let $V=\R^n$. Define vector addition on $V$ to be the usual $n$-vector addition, but define scalar multiplication as 
\[
r(v_1,v_2,\dots ,v_n)=(r^2v_1,r^2v_2,\dots, r^2v_n). 
\]
Show that $V$ is NOT a vector space with these choices of vector addition and scalar multiplication.
\\
\begin{solution}
This choice of vector addition and scalar multiplication fails the following distributivity axiom:
\[
(r+s)\boldv=r\boldv+s\boldv.
\]
Indeed take $r=s=1$, and $\boldv=(1,1,\dots,1)$. Then on the one hand we have 
\[
(r+s)\boldv=(1+1)\boldv=2(1,1,\dots,1)=(4,4,\dots, 4), \]
using the given definition of scalar multiplication. 

On the other hand we have 
\[
r\boldv+s\boldv=1(1,1,\dots,1)+1(1,1,\dots,1)=(1,1,\dots,1)+(1,1,\dots,1)=(2,2,\dots,2),
\]
again using the given definitions of scalar mult. and vector addition. 

Thus we see that 
\[
(r+s)\boldv\ne r\boldv+s\boldv
\]
for this choice of $r,s$ and $\boldv$, and conclude the given set and operations do not form a vector space. 
\end{solution}
\ii Let $V=\{(x,y)\in\R^2\colon x>0, \ y<0\}$: i.e., $V$ is the set of pairs whose first component is positive, and whose second component is negative. The following operations satisfy the axioms of a vector space.  
\\
{\bf Vector addition}: $(x_1,\ y_1)+(x_2,\ y_2)=(x_1 x_2,\ -y_1 y_2)$. \\
(In other words, vector addition takes the product of the first components, and takes the negative of the product of the second components. )
\vspace{.1in}
\\
{\bf Scalar multiplication}: $r(x,\ y)=(x^r,\  -\val{y}^r)$.

Below you are asked to verify some (but not all!) of the vector space axioms.   
\bb
\ii Explicitly identify the element of $V$ that acts as the additive identity $\boldzero$ with respect to the above vector operations. 

Show directly that your choice of $\boldzero$ satisfies $\boldzero+\boldv=\boldv$ for all $\boldv=(x,y)\in V$. 

Caution: at the very least, the $\boldzero$ you provide should be an actual element of the given $V$. For example, note that $(0,0)$ is not even an element of $V$ !!
\ii Given $\boldv=(x,y)\in V$, give a formula in terms of $x$ and $y$ for its additive inverse $-\boldv$ with respect to the above vector operations.

Show directly that your formula for $-\boldv$ satisfies $\boldv+ (-\boldv)=\boldzero$. Again, you must always use the definition of the vector space operations given above.
\ii Prove that Axiom (h) holds: i.e., that $1\boldv=\boldv$ for all $\boldv\in V$.  
\ee
\begin{solution}
\noindent
(a) The additive identity for the given vector space is $\boldzero=(1,-1)$. 

\noindent
Proof:
\begin{align*}
(1,-1)+(x,y)&=(1x,-(-1)y) &\text{(def. of vect. add.)}\\
&=(x,y)
\end{align*}
(b) Given element $\boldv=(x,y)\in V$, its additive inverse is $-\boldv=\left(\frac{1}{x},\frac{1}{y}\right)$. 

\noindent
Proof:
\begin{align*}
(x,y)+\left(\frac{1}{x},\frac{1}{y}\right)&=\left(x\ \frac{1}{x},-y\ \frac{1}{y}\right) &\text{(def. of vect. add.)}\\
&=(1,-1)\\
&=\boldzero &\text{(since $\boldzero=(1,-1)$)}
\end{align*}
(c) Proof:
\begin{align*}
1(x,y)&=(x^1,-\val{y}^1) &\text{(def. of scalar mult.)}\\
&=(x,-\val{y})\\
&=(x,y). 
\end{align*}
The last equality in the proof above follows from the definition of absolute value: for $y<0$, we have by definition $\val{y}=-y$. 
\end{solution}

\ii Let $V=\{f(x)=1+ax\colon a\in\R\}$ be the set of all linear polynomials $f(x)$ with constant coefficient 1: i.e., $f(0)=1$. Define:
\begin{align*}
\text{Vector addition:} \ (1+ax)+(1+bx)&:= (1+ax)(1+bx)-abx^2\\
\text{Scalar multiplication:}\  r\cdot (1+ax):=1+rax 
\end{align*}
Prove $V$ along with these operations forms a vector space. Make explicit what the additive identity and inverses are. 
\\
\begin{solution}
If you expand and simplify the expression $(1+ax)(1+bx)-abx^2$ you get $1+(a+b)x$. This shows that our vector addition is well-defined on the set $V$; it is clear that our scalar multiplication is also well-defined. 

An element $f(x)=1+ax$ is completely determined by the coefficient $a$, so let's denote $f_a(x)=1+ax$. Our vector operations have a very simple description using this notation:
\begin{align*}
f_a(x)+f_b(x)&=f_{a+b}(x)\\
r\cdot f_a(x)&=f_{ra}(x).
\end{align*}
In other words we see that our ``fancy" vector operations boil down to the usual addition $a+b$, and multiplication $r\cdot a$. Once this it is clear, it is obvious that the operations satisfy the vector space axioms. 

The additive identity is $\boldzero=f_0(x)=1+0x=1$, the constant function equal to 1. Additive inverses are given by the formula $-f_a(x)=f_{-a}(x)$; i.e., the additive inverse of $f(x)=1+ax$ is $g(x)=1-ax$.  
\end{solution}
\ii Let $V=\R^2$. The following operations do {\bf NOT} satisfy all of the vector space axioms. 

{\bf Vector addition}: $(x_1,y_1)+(x_2,y_2)=(x_1+y_1,x_2+y_2)$. (The usual vector addition on $\R^2$.)

\noindent
{\bf Scalar multiplciation}: $r(x,y)=(rx,0)$. 
\bb
\ii Verify that these operations satisfy Axiom (f): i.e., that $(r+s)\boldv=r\boldv+s\boldv$ for all $r,s\in\R$ and all $(x,y)\in\R^2$. 
\ii Find an axiom that these operations do {\bf NOT} satisfy, and provide an explicit counterexample showing that the axiom fails. 
\ee
\begin{solution}
 \noindent
 (a) We have 
 \begin{align*}
 (r+s)(x,y)&=((r+s)x,0) &\text{(by def. of scal. mult.)}\\
 &=(rx+sx,0) &\text{(real number arith.)}\\
 &=(rx,0)+(sx,0) &\text{(by def. of vector add.)}\\
 &=r(x,0)+s(x,0) &\text{(by def. of scal. mult.)}.
 \end{align*}
(b) The given operations do not satisfy axiom (h). By definition we have $1(x,y)=(x,0)$. This will not be equal to $(x,y)$ unless $y=0$. 
 \end{solution}
\ii Prove the vector space properties theorem. (Some of these parts have been proved in the lecture notes or elsewhere. No matter, recreate those proofs or produce new ones!) 
\\
\begin{solution}
\noindent
The theorem states that, given a vector space $V$, the properties below hold. 
\bb[(a)]
\ii $0\boldv=\boldzero$ for all $\boldv\in V$. 
\ii $k\boldzero=\boldzero$ for all $k\in \R$. 
\ii $(-1)\boldv=-\boldv$ for all $\boldv\in V$. 
\ii If $k\boldu=\boldzero$, then $k=0$ or $\boldu=\boldzero$. 
\ee
We have proved (a) and (c) somewhere (lecture notes, video examples, class, etc.).
\\
It remains to prove (b) and (d). I may make use of properties (a) and (c), since these are already proven. 
\\
Let's prove (b). From (a) we know that if $k=0$, then $k\boldzero=0\boldzero=\boldzero$. Suppose $k\ne 0$. Then we have 
\begin{align*}
k\boldzero&=k(\boldzero+\boldzero) &\text{($\boldzero+\boldzero=\boldzero$)}\\
&=k\boldzero+k\boldzero &\text{(dist. prop.)}
\end{align*}
Thus $k\boldzero=k\boldzero+k\boldzero$. Now add the additive identity $-k\boldzero$ to both sides of this equation to ``cancel" one of the $k\boldzero$. We are left with $\boldzero=k\boldzero$, as desired. 
\vspace{.1in}
\\
Finally, we prove (d). Suppose $k\boldu=\boldzero$ and that $k\ne 0$. Then $k$ has a multiplicative inverse $\frac{1}{k}$. Then 
\begin{align*}
k\boldu=\boldzero&\Rightarrow \frac{1}{k}(k\boldu)=\frac{1}{k}\boldzero\\
&\Rightarrow (\frac{1}{k}k)\boldu=\boldzero &\text{(assoc. and property (b))}\\
&\Rightarrow 1\boldu=\boldzero\\
&\Rightarrow \boldu=\boldzero &\text{(since $1\boldu=\boldu$)}.
\end{align*}
We have shown that if $k\boldu=\boldzero$ and $k\ne 0$, then $\boldu=\boldzero$. Logically, this is equivalent to showing if $k\boldu=\boldzero$, then $k=0$ or $\boldu=0$. 
\end{solution}
\ii Prove that a vector space $V$ is either trivial (i.e., $V=\{\boldzero\}$) or infinite. Hint: if $\boldv\ne\boldzero$, show that $r\boldv\ne s\boldv$ for two distinct real numbers $r\ne s$. 
%This means unfortunately that the only basket of apples we can put a real vector space structure on is the basket that contains exactly 1 apple. That said, there is the possibility of putting a $\mathbb{F}_p$-vector space structure on apple baskets, where $p$ is prime, but that is a topic for another course!  
\\
\begin{solution}
Suppose $V$ is nontrivial. Then there is a nonzero $\boldv\ne \boldzero$ in $V$. Then for each $r\in\R$ the vector $r\boldv$ is also an element of $V$. To show that $V$ infinite we need only show that all of these $r\boldv$ are distinct; i.e., we must show that if $r\ne s$, then $r\boldv\ne s\boldv$. 

(Note: we cannot take this for granted, but must actually prove it. For all we know we could have $r\boldv=\boldv$ for all $r\in\R$.) 

We prove the contrapositive. Suppose $r\boldv=s\boldv$. Then $r\boldv-s\boldv=\boldzero$. Then $(r-s)\boldv=\boldzero$. I now claim that since $\boldv\ne\boldzero$, we must have $r-s=0$, and hence $r=s$. 

Indeed suppose $a\boldv=\boldzero$ and $a\ne 0$. Since $a\ne 0$, we can multiply both sides of this equation by $\frac{1}{a}$:
\begin{align*}
\frac{1}{a}(a\boldv)&=\frac{1}{a}\boldzero\\
(\frac{1}{a}\cdot a)\boldv&=\boldzero &\text{(assoc. of scalar mult; $c\boldzero=\boldzero$)}\\
1\boldv&=\boldzero\\
\boldv&=\boldzero &\text{(Axiom: $1\boldv=\boldv$)}
\end{align*}
That concludes our (longer than expected) proof that if $r\ne s$, then $r\boldv\ne s\boldv$, which proves that $V$ is infinite. 
\end{solution}
\ii Let $V$ be a vector space. Show that for all $\boldv\in V$ there is a unique additive inverse for $\boldv$. That is, show if $\boldv+\boldw=\boldzero$, then $\boldw=-\boldv$.  
\\
\begin{solution}
Fix $\boldv$ and suppose $\boldw$ also satisfies $\boldv+\boldw=\boldzero$. Then  
\[
\boldv+-\boldv=\boldzero=\boldv+\boldw.
\]
Then we have 
\begin{align*}
\boldv+(-\boldv)&=\boldv+\boldw\\
-\boldv+\boldv+(-\boldv)&=-\boldv+\boldv+\boldw\\
\boldzero+(-\boldv)&=\boldzero+\boldw\\
-\boldv&=\boldw,
\end{align*}
as desired. 
\end{solution}
\ii Let $V$ be a vector space. Prove, using only the axioms of a vector space: if $\boldu + \boldw = \boldv + \boldw$, then $\boldu = \boldv$.
\\
\begin{solution}
\begin{eqnarray*}
\boldu + \boldw = \boldv + \boldw&\text{(Hypothesis)}\\
(\boldu + \boldw) + (-\boldw) = (\boldv + \boldw) + (-\boldw) &\text{(Add -\textbf{w} to both sides)}\\
\boldu + [\boldw + (-\boldw)] = \boldv + [\boldw + (-\boldw)] &\text{(Axiom 3)}\\
\boldu + \bold0 = \boldv + \bold0 &\text{(Axiom 5)}\\
\boldu = \boldv &\text{(Axiom 4)}
\end{eqnarray*}
\end{solution}


\ee